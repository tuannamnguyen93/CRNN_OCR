{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import joblib\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, Lambda, Flatten, Activation, Input, Reshape, LSTM, Dense, add, concatenate, MaxPooling2D, BatchNormalization\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras import backend as K\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.backend.tensorflow_backend import set_session\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "# config.gpu_options.visible_device_list = \"0\"\n",
    "# set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_out(inputs, num_units, axis=None):\n",
    "    shape = inputs.get_shape().as_list()\n",
    "    if shape[0] is None:\n",
    "        shape[0] = -1\n",
    "    if axis is None:  # Assume that channel is the last dimension\n",
    "        axis = -1\n",
    "    num_channels = shape[axis]\n",
    "    if num_channels % num_units:\n",
    "        raise ValueError('number of features({}) is not a multiple of num_units({})'.format(num_channels, num_units))\n",
    "    shape[axis] = num_units\n",
    "    shape += [num_channels // num_units]\n",
    "    outputs = tf.reduce_max(tf.reshape(inputs, shape), -1, keepdims=False)\n",
    "    return outputs\n",
    "\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sequences_20_all_same_train.txt\", \"r\") as f:\n",
    "    seq_labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(a,b):\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    list3 = []\n",
    "    for i in range(a, b):\n",
    "        img = cv2.imread(\"../data/Seq_data_20_all_same_train/\" + \"Sequence_\" + str(i) + \".png\")\n",
    "        ratio = int(round((float(img.shape[1])/float(img.shape[0]))*32))\n",
    "        img = cv2.resize(img,(ratio,32))\n",
    "        \n",
    "#         seq=seq_labels[\"Sequence_\" + str(i) + \".png\"] \n",
    "        \n",
    "        list1.append(img)\n",
    "#         list2.append([-1 if x==72 else x for x in seq])\n",
    "        list2.append(seq_labels[\"Sequence_\" + str(i) + \".png\"])\n",
    "#         list3.append(len(filter(lambda a: a != 72, seq)))\n",
    "        print i\n",
    "\n",
    "    arr1 = np.asarray(list1, dtype=np.float32)\n",
    "    arr2 = np.asarray(list2, dtype=np.int64)\n",
    "#     arr3 = np.asarray(list3, dtype=np.int64)\n",
    "    \n",
    "    return arr1, arr2,np.ones((b-a,1))*572,np.ones((b-a,1))*20, ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99, 32, 581, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print input_data.shape\n",
    "plt.imshow(input_data[7])\n",
    "seq_labels[\"Sequence_\" + \"3\"+ \".png\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    _,_,_,_,ratio = get_data(1,5)\n",
    "\n",
    "    input_maxout = Input(name='the_input', shape=(32,ratio,3), dtype='float32')\n",
    "\n",
    "    inner = Conv2D(16, (3,3), padding='valid', activation='relu', data_format=\"channels_last\", name='conv1')(input_maxout)\n",
    "\n",
    "    inner = BatchNormalization()(inner)\n",
    "\n",
    "    inner = MaxPooling2D(pool_size=(2, 1))(inner)\n",
    "\n",
    "    print inner.shape\n",
    "\n",
    "    inner = Conv2D(32, (3,3), padding='valid', activation='relu', data_format=\"channels_last\", name='conv2')(inner)\n",
    "\n",
    "    inner = BatchNormalization()(inner)\n",
    "\n",
    "    inner = MaxPooling2D(pool_size=(2, 1))(inner)\n",
    "\n",
    "    print inner.shape\n",
    "\n",
    "    inner = Conv2D(64, (3,3), padding='valid', activation='relu', data_format=\"channels_last\", name='conv3')(inner)\n",
    "\n",
    "    inner = BatchNormalization()(inner)\n",
    "\n",
    "    inner = MaxPooling2D(pool_size=(2, 1))(inner)\n",
    "\n",
    "    print inner.shape\n",
    "\n",
    "    inner = Conv2D(128, (2,2), padding='valid', activation='relu', data_format=\"channels_last\", name='conv4')(inner)\n",
    "\n",
    "    #inner = BatchNormalization()(inner)\n",
    "\n",
    "    #inner = MaxPooling2D(pool_size=(2, 1))(inner)\n",
    "\n",
    "    print inner.shape\n",
    "\n",
    "    output = Reshape([574,128])(inner)\n",
    "\n",
    "    lstm_1=LSTM(128,return_sequences=True,kernel_initializer='he_normal',name='lstm1')(output)\n",
    "\n",
    "    lstm_1b=LSTM(128,return_sequences=True,go_backwards=True,kernel_initializer='he_normal',name='lstm1b')(output)\n",
    "\n",
    "    lstm_merge=concatenate([lstm_1,lstm_1b])\n",
    "\n",
    "    inner = Dense(3138, kernel_initializer='he_normal', name='dense')(lstm_merge)\n",
    "    \n",
    "#     inner = TimeDistributed(Dense(73, kernel_initializer='he_normal', name='dense'))(lstm_merge)\n",
    "\n",
    "    y_pred = Activation('softmax',name='softmax')(inner)\n",
    "\n",
    "    labels = Input(name='the_labels', shape=[20], dtype='int64')\n",
    "\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "\n",
    "    labels_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, labels_length])\n",
    "\n",
    "    model = Model(inputs=[input_maxout, labels, input_length, labels_length], outputs=loss_out)\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "(?, 15, 579, 16)\n",
      "(?, 6, 577, 32)\n",
      "(?, 2, 575, 64)\n",
      "(?, 1, 574, 128)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          (None, 32, 581, 3)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 30, 579, 16)  448         the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 30, 579, 16)  64          conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 15, 579, 16)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 13, 577, 32)  4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 13, 577, 32)  128         conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 6, 577, 32)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 4, 575, 64)   18496       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 4, 575, 64)   256         conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 2, 575, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4 (Conv2D)                  (None, 1, 574, 128)  32896       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 574, 128)     0           conv4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lstm1 (LSTM)                    (None, 574, 128)     131584      reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm1b (LSTM)                   (None, 574, 128)     131584      reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 574, 256)     0           lstm1[0][0]                      \n",
      "                                                                 lstm1b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 574, 73)      18761       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 574, 73)      0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "the_labels (InputLayer)         (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "label_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc (Lambda)                    (None, 1)            0           softmax[0][0]                    \n",
      "                                                                 the_labels[0][0]                 \n",
      "                                                                 input_length[0][0]               \n",
      "                                                                 label_length[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 338,857\n",
      "Trainable params: 338,633\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/4\n",
      "90000/90000 [==============================] - 3295s 37ms/step - loss: 34.7347\n",
      "Epoch 2/4\n",
      "73568/90000 [=======================>......] - ETA: 9:49 - loss: 0.4805"
     ]
    }
   ],
   "source": [
    "def train_model():\n",
    "    m = model()\n",
    "\n",
    "    # optimizer = SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n",
    "\n",
    "    m.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer='adam')\n",
    "\n",
    "    Y = np.zeros((100000, 1))\n",
    "    for epoch in range(0,3):\n",
    "        print epoch\n",
    "        for i in range(0,20):\n",
    "            input_data, labels, input_length, labels_length,_ = get_data(i*100000+1, (i+1)*100000+1)\n",
    "\n",
    "            m.fit([input_data, labels, input_length, labels_length], Y, batch_size=32, epochs=1)\n",
    "        \n",
    "\n",
    "            m.save('first_try_CNN_LSTM_CTC_10.h5')\n",
    "\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
