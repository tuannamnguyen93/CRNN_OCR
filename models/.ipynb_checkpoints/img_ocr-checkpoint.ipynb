{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import codecs\n",
    "import re\n",
    "import datetime\n",
    "import cairocffi as cairo\n",
    "import editdistance\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import pylab\n",
    "from keras import backend as K\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Input, Dense, Activation\n",
    "from keras.layers import Reshape, Lambda\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing import image\n",
    "import keras.callbacks\n",
    "\n",
    "\n",
    "OUTPUT_DIR = 'image_ocr'\n",
    "\n",
    "# character classes and matching regex filter\n",
    "regex = r'^[a-z ]+$'\n",
    "alphabet = u'abcdefghijklmnopqrstuvwxyz '\n",
    "\n",
    "np.random.seed(55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speckle(img):\n",
    "    severity = np.random.uniform(0, 0.6)\n",
    "    blur = ndimage.gaussian_filter(np.random.randn(*img.shape) * severity, 1)\n",
    "    img_speck = (img + blur)\n",
    "    img_speck[img_speck > 1] = 1\n",
    "    img_speck[img_speck <= 0] = 0\n",
    "    return img_speck\n",
    "\n",
    "\n",
    "# paints the string in a random location the bounding box\n",
    "# also uses a random font, a slight random rotation,\n",
    "# and a random amount of speckle noise\n",
    "\n",
    "def paint_text(text, w, h, rotate=False, ud=False, multi_fonts=False):\n",
    "    surface = cairo.ImageSurface(cairo.FORMAT_RGB24, w, h)\n",
    "    with cairo.Context(surface) as context:\n",
    "        context.set_source_rgb(1, 1, 1)  # White\n",
    "        context.paint()\n",
    "        # this font list works in CentOS 7\n",
    "        if multi_fonts:\n",
    "            fonts = ['Century Schoolbook', 'Courier', 'STIX', 'URW Chancery L', 'FreeMono']\n",
    "            context.select_font_face(np.random.choice(fonts), cairo.FONT_SLANT_NORMAL,\n",
    "                                     np.random.choice([cairo.FONT_WEIGHT_BOLD, cairo.FONT_WEIGHT_NORMAL]))\n",
    "        else:\n",
    "            context.select_font_face('Courier', cairo.FONT_SLANT_NORMAL, cairo.FONT_WEIGHT_BOLD)\n",
    "        context.set_font_size(25)\n",
    "        box = context.text_extents(text)\n",
    "        border_w_h = (4, 4)\n",
    "        if box[2] > (w - 2 * border_w_h[1]) or box[3] > (h - 2 * border_w_h[0]):\n",
    "            raise IOError('Could not fit string into image. Max char count is too large for given image width.')\n",
    "\n",
    "        # teach the RNN translational invariance by\n",
    "        # fitting text box randomly on canvas, with some room to rotate\n",
    "        max_shift_x = w - box[2] - border_w_h[0]\n",
    "        max_shift_y = h - box[3] - border_w_h[1]\n",
    "        top_left_x = np.random.randint(0, int(max_shift_x))\n",
    "        if ud:\n",
    "            top_left_y = np.random.randint(0, int(max_shift_y))\n",
    "        else:\n",
    "            top_left_y = h // 2\n",
    "        context.move_to(top_left_x - int(box[0]), top_left_y - int(box[1]))\n",
    "        context.set_source_rgb(0, 0, 0)\n",
    "        context.show_text(text)\n",
    "\n",
    "    buf = surface.get_data()\n",
    "    a = np.frombuffer(buf, np.uint8)\n",
    "    a.shape = (h, w, 4)\n",
    "    a = a[:, :, 0]  # grab single channel\n",
    "    a = a.astype(np.float32) / 255\n",
    "    a = np.expand_dims(a, 0)\n",
    "    if rotate:\n",
    "        a = image.random_rotation(a, 3 * (w - top_left_x) / w + 1)\n",
    "    a = speckle(a)\n",
    "\n",
    "    return a\n",
    "\n",
    "\n",
    "def shuffle_mats_or_lists(matrix_list, stop_ind=None):\n",
    "    ret = []\n",
    "    assert all([len(i) == len(matrix_list[0]) for i in matrix_list])\n",
    "    len_val = len(matrix_list[0])\n",
    "    if stop_ind is None:\n",
    "        stop_ind = len_val\n",
    "    assert stop_ind <= len_val\n",
    "\n",
    "    a = list(range(stop_ind))\n",
    "    np.random.shuffle(a)\n",
    "    a += list(range(stop_ind, len_val))\n",
    "    for mat in matrix_list:\n",
    "        if isinstance(mat, np.ndarray):\n",
    "            ret.append(mat[a])\n",
    "        elif isinstance(mat, list):\n",
    "            ret.append([mat[i] for i in a])\n",
    "        else:\n",
    "            raise TypeError('`shuffle_mats_or_lists` only supports '\n",
    "                            'numpy.array and list objects.')\n",
    "    return ret\n",
    "\n",
    "\n",
    "# Translation of characters to unique integer values\n",
    "def text_to_labels(text):\n",
    "    ret = []\n",
    "    for char in text:\n",
    "        ret.append(alphabet.find(char))\n",
    "    return ret\n",
    "\n",
    "\n",
    "# Reverse translation of numerical classes back to characters\n",
    "def labels_to_text(labels):\n",
    "    ret = []\n",
    "    for c in labels:\n",
    "        if c == len(alphabet):  # CTC Blank\n",
    "            ret.append(\"\")\n",
    "        else:\n",
    "            ret.append(alphabet[c])\n",
    "    return \"\".join(ret)\n",
    "\n",
    "\n",
    "# only a-z and space..probably not to difficult\n",
    "# to expand to uppercase and symbols\n",
    "\n",
    "def is_valid_str(in_str):\n",
    "    search = re.compile(regex, re.UNICODE).search\n",
    "    return bool(search(in_str))\n",
    "\n",
    "\n",
    "# Uses generator functions to supply train/test with\n",
    "# data. Image renderings are text are created on the fly\n",
    "# each time with random perturbations\n",
    "\n",
    "class TextImageGenerator(keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, monogram_file, bigram_file, minibatch_size,\n",
    "                 img_w, img_h, downsample_factor, val_split,\n",
    "                 absolute_max_string_len=16):\n",
    "\n",
    "        self.minibatch_size = minibatch_size\n",
    "        self.img_w = img_w\n",
    "        self.img_h = img_h\n",
    "        self.monogram_file = monogram_file\n",
    "        self.bigram_file = bigram_file\n",
    "        self.downsample_factor = downsample_factor\n",
    "        self.val_split = val_split\n",
    "        self.blank_label = self.get_output_size() - 1\n",
    "        self.absolute_max_string_len = absolute_max_string_len\n",
    "\n",
    "    def get_output_size(self):\n",
    "        return len(alphabet) + 1\n",
    "\n",
    "    # num_words can be independent of the epoch size due to the use of generators\n",
    "    # as max_string_len grows, num_words can grow\n",
    "    def build_word_list(self, num_words, max_string_len=None, mono_fraction=0.5):\n",
    "        assert max_string_len <= self.absolute_max_string_len\n",
    "        assert num_words % self.minibatch_size == 0\n",
    "        assert (self.val_split * num_words) % self.minibatch_size == 0\n",
    "        self.num_words = num_words\n",
    "        self.string_list = [''] * self.num_words\n",
    "        tmp_string_list = []\n",
    "        self.max_string_len = max_string_len\n",
    "        self.Y_data = np.ones([self.num_words, self.absolute_max_string_len]) * -1\n",
    "        self.X_text = []\n",
    "        self.Y_len = [0] * self.num_words\n",
    "\n",
    "        # monogram file is sorted by frequency in english speech\n",
    "        with codecs.open(self.monogram_file, mode='r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                if len(tmp_string_list) == int(self.num_words * mono_fraction):\n",
    "                    break\n",
    "                word = line.rstrip()\n",
    "                if max_string_len == -1 or max_string_len is None or len(word) <= max_string_len:\n",
    "                    tmp_string_list.append(word)\n",
    "\n",
    "        # bigram file contains common word pairings in english speech\n",
    "        with codecs.open(self.bigram_file, mode='r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                if len(tmp_string_list) == self.num_words:\n",
    "                    break\n",
    "                columns = line.lower().split()\n",
    "                word = columns[0] + ' ' + columns[1]\n",
    "                if is_valid_str(word) and \\\n",
    "                        (max_string_len == -1 or max_string_len is None or len(word) <= max_string_len):\n",
    "                    tmp_string_list.append(word)\n",
    "        if len(tmp_string_list) != self.num_words:\n",
    "            raise IOError('Could not pull enough words from supplied monogram and bigram files. ')\n",
    "        # interlace to mix up the easy and hard words\n",
    "        self.string_list[::2] = tmp_string_list[:self.num_words // 2]\n",
    "        self.string_list[1::2] = tmp_string_list[self.num_words // 2:]\n",
    "\n",
    "        for i, word in enumerate(self.string_list):\n",
    "            self.Y_len[i] = len(word)\n",
    "            self.Y_data[i, 0:len(word)] = text_to_labels(word)\n",
    "            self.X_text.append(word)\n",
    "        self.Y_len = np.expand_dims(np.array(self.Y_len), 1)\n",
    "\n",
    "        self.cur_val_index = self.val_split\n",
    "        self.cur_train_index = 0\n",
    "\n",
    "    # each time an image is requested from train/val/test, a new random\n",
    "    # painting of the text is performed\n",
    "    def get_batch(self, index, size, train):\n",
    "        # width and height are backwards from typical Keras convention\n",
    "        # because width is the time dimension when it gets fed into the RNN\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            X_data = np.ones([size, 1, self.img_w, self.img_h])\n",
    "        else:\n",
    "            X_data = np.ones([size, self.img_w, self.img_h, 1])\n",
    "\n",
    "        labels = np.ones([size, self.absolute_max_string_len])\n",
    "        input_length = np.zeros([size, 1])\n",
    "        label_length = np.zeros([size, 1])\n",
    "        source_str = []\n",
    "        for i in range(size):\n",
    "            # Mix in some blank inputs.  This seems to be important for\n",
    "            # achieving translational invariance\n",
    "            if train and i > size - 4:\n",
    "                if K.image_data_format() == 'channels_first':\n",
    "                    X_data[i, 0, 0:self.img_w, :] = self.paint_func('')[0, :, :].T\n",
    "                else:\n",
    "                    X_data[i, 0:self.img_w, :, 0] = self.paint_func('',)[0, :, :].T\n",
    "                labels[i, 0] = self.blank_label\n",
    "                input_length[i] = self.img_w // self.downsample_factor - 2\n",
    "                label_length[i] = 1\n",
    "                source_str.append('')\n",
    "            else:\n",
    "                if K.image_data_format() == 'channels_first':\n",
    "                    X_data[i, 0, 0:self.img_w, :] = self.paint_func(self.X_text[index + i])[0, :, :].T\n",
    "                else:\n",
    "                    X_data[i, 0:self.img_w, :, 0] = self.paint_func(self.X_text[index + i])[0, :, :].T\n",
    "                labels[i, :] = self.Y_data[index + i]\n",
    "                input_length[i] = self.img_w // self.downsample_factor - 2\n",
    "                label_length[i] = self.Y_len[index + i]\n",
    "                source_str.append(self.X_text[index + i])\n",
    "        inputs = {'the_input': X_data,\n",
    "                  'the_labels': labels,\n",
    "                  'input_length': input_length,\n",
    "                  'label_length': label_length,\n",
    "                  'source_str': source_str  # used for visualization only\n",
    "                  }\n",
    "        outputs = {'ctc': np.zeros([size])} \n",
    "     # dummy data for dummy loss function\n",
    "        return (inputs, outputs)\n",
    "\n",
    "    def next_train(self):\n",
    "        while 1:\n",
    "            ret = self.get_batch(self.cur_train_index, self.minibatch_size, train=True)\n",
    "            self.cur_train_index += self.minibatch_size\n",
    "            if self.cur_train_index >= self.val_split:\n",
    "                self.cur_train_index = self.cur_train_index % 32\n",
    "                (self.X_text, self.Y_data, self.Y_len) = shuffle_mats_or_lists(\n",
    "                    [self.X_text, self.Y_data, self.Y_len], self.val_split)\n",
    "            print self.Y_data\n",
    "            yield ret\n",
    "\n",
    "    def next_val(self):\n",
    "        while 1:\n",
    "            ret = self.get_batch(self.cur_val_index, self.minibatch_size, train=False)\n",
    "            self.cur_val_index += self.minibatch_size\n",
    "            if self.cur_val_index >= self.num_words:\n",
    "                self.cur_val_index = self.val_split + self.cur_val_index % 32\n",
    "            yield ret\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.build_word_list(16000, 4, 1)\n",
    "        self.paint_func = lambda text: paint_text(text, self.img_w, self.img_h,\n",
    "                                                  rotate=False, ud=False, multi_fonts=False)\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        # rebind the paint function to implement curriculum learning\n",
    "        if 3 <= epoch < 6:\n",
    "            self.paint_func = lambda text: paint_text(text, self.img_w, self.img_h,\n",
    "                                                      rotate=False, ud=True, multi_fonts=False)\n",
    "        elif 6 <= epoch < 9:\n",
    "            self.paint_func = lambda text: paint_text(text, self.img_w, self.img_h,\n",
    "                                                      rotate=False, ud=True, multi_fonts=True)\n",
    "        elif epoch >= 9:\n",
    "            self.paint_func = lambda text: paint_text(text, self.img_w, self.img_h,\n",
    "                                                      rotate=True, ud=True, multi_fonts=True)\n",
    "        if epoch >= 21 and self.max_string_len < 12:\n",
    "            self.build_word_list(32000, 12, 0.5)\n",
    "\n",
    "\n",
    "# the actual loss calc occurs here despite it not being\n",
    "# an internal Keras loss function\n",
    "\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # the 2 is critical here since the first couple outputs of the RNN\n",
    "    # tend to be garbage:\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "\n",
    "# For a real OCR application, this should be beam search with a dictionary\n",
    "# and language model.  For this example, best path is sufficient.\n",
    "\n",
    "def decode_batch(test_func, word_batch):\n",
    "    out = test_func([word_batch])[0]\n",
    "    ret = []\n",
    "    for j in range(out.shape[0]):\n",
    "        out_best = list(np.argmax(out[j, 2:], 1))\n",
    "        out_best = [k for k, g in itertools.groupby(out_best)]\n",
    "        outstr = labels_to_text(out_best)\n",
    "        ret.append(outstr)\n",
    "    return ret\n",
    "\n",
    "\n",
    "class VizCallback(keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, run_name, test_func, text_img_gen, num_display_words=6):\n",
    "        self.test_func = test_func\n",
    "        self.output_dir = os.path.join(\n",
    "            OUTPUT_DIR, run_name)\n",
    "        self.text_img_gen = text_img_gen\n",
    "        self.num_display_words = num_display_words\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "    def show_edit_distance(self, num):\n",
    "        num_left = num\n",
    "        mean_norm_ed = 0.0\n",
    "        mean_ed = 0.0\n",
    "        while num_left > 0:\n",
    "            word_batch = next(self.text_img_gen)[0]\n",
    "        \n",
    "            num_proc = min(word_batch['the_input'].shape[0], num_left)\n",
    "            decoded_res = decode_batch(self.test_func, word_batch['the_input'][0:num_proc])\n",
    "            for j in range(num_proc):\n",
    "                edit_dist = editdistance.eval(decoded_res[j], word_batch['source_str'][j])\n",
    "                mean_ed += float(edit_dist)\n",
    "                mean_norm_ed += float(edit_dist) / len(word_batch['source_str'][j])\n",
    "            num_left -= num_proc\n",
    "        mean_norm_ed = mean_norm_ed / num\n",
    "        mean_ed = mean_ed / num\n",
    "        print('\\nOut of %d samples:  Mean edit distance: %.3f Mean normalized edit distance: %0.3f'\n",
    "              % (num, mean_ed, mean_norm_ed))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.model.save_weights(os.path.join(self.output_dir, 'weights%02d.h5' % (epoch)))\n",
    "        self.show_edit_distance(256)\n",
    "        word_batch = next(self.text_img_gen)[0]\n",
    "        res = decode_batch(self.test_func, word_batch['the_input'][0:self.num_display_words])\n",
    "        if word_batch['the_input'][0].shape[0] < 256:\n",
    "            cols = 2\n",
    "        else:\n",
    "            cols = 1\n",
    "        for i in range(self.num_display_words):\n",
    "            pylab.subplot(self.num_display_words // cols, cols, i + 1)\n",
    "            if K.image_data_format() == 'channels_first':\n",
    "                the_input = word_batch['the_input'][i, 0, :, :]\n",
    "            else:\n",
    "                the_input = word_batch['the_input'][i, :, :, 0]\n",
    "            pylab.imshow(the_input.T, cmap='Greys_r')\n",
    "            pylab.xlabel('Truth = \\'%s\\'\\nDecoded = \\'%s\\'' % (word_batch['source_str'][i], res[i]))\n",
    "        fig = pylab.gcf()\n",
    "        fig.set_size_inches(10, 13)\n",
    "        pylab.savefig(os.path.join(self.output_dir, 'e%02d.png' % (epoch)))\n",
    "        pylab.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(run_name, start_epoch, stop_epoch, img_w):\n",
    "    # Input Parameters\n",
    "    img_h = 64\n",
    "    words_per_epoch = 16000\n",
    "    val_split = 0.2\n",
    "    val_words = int(words_per_epoch * (val_split))\n",
    "\n",
    "    # Network parameters\n",
    "    conv_filters = 16\n",
    "    kernel_size = (3, 3)\n",
    "    pool_size = 2\n",
    "    time_dense_size = 32\n",
    "    rnn_size = 512\n",
    "    minibatch_size = 32\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_shape = (1, img_w, img_h)\n",
    "    else:\n",
    "        input_shape = (img_w, img_h, 1)\n",
    "\n",
    "    fdir = os.path.dirname(get_file('wordlists.tgz',\n",
    "                                    origin='http://www.mythic-ai.com/datasets/wordlists.tgz', untar=True))\n",
    "\n",
    "    img_gen = TextImageGenerator(monogram_file=os.path.join(fdir, 'wordlist_mono_clean.txt'),\n",
    "                                 bigram_file=os.path.join(fdir, 'wordlist_bi_clean.txt'),\n",
    "                                 minibatch_size=minibatch_size,\n",
    "                                 img_w=img_w,\n",
    "                                 img_h=img_h,\n",
    "                                 downsample_factor=(pool_size ** 2),\n",
    "                                 val_split=words_per_epoch - val_words\n",
    "                                 )\n",
    "    act = 'relu'\n",
    "    input_data = Input(name='the_input', shape=input_shape, dtype='float32')\n",
    "    inner = Conv2D(conv_filters, kernel_size, padding='same',\n",
    "                   activation=act, kernel_initializer='he_normal',\n",
    "                   name='conv1')(input_data)\n",
    "    inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max1')(inner)\n",
    "    inner = Conv2D(conv_filters, kernel_size, padding='same',\n",
    "                   activation=act, kernel_initializer='he_normal',\n",
    "                   name='conv2')(inner)\n",
    "    inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max2')(inner)\n",
    "\n",
    "    conv_to_rnn_dims = (img_w // (pool_size ** 2), (img_h // (pool_size ** 2)) * conv_filters)\n",
    "    inner = Reshape(target_shape=conv_to_rnn_dims, name='reshape')(inner)\n",
    "\n",
    "    # cuts down input size going into RNN:\n",
    "    inner = Dense(time_dense_size, activation=act, name='dense1')(inner)\n",
    "\n",
    "    # Two layers of bidirectional GRUs\n",
    "    # GRU seems to work as well, if not better than LSTM:\n",
    "    gru_1 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru1')(inner)\n",
    "    gru_1b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru1_b')(inner)\n",
    "    gru1_merged = add([gru_1, gru_1b])\n",
    "    gru_2 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru2')(gru1_merged)\n",
    "    gru_2b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru2_b')(gru1_merged)\n",
    "\n",
    "    # transforms RNN output to character activations:\n",
    "    inner = Dense(img_gen.get_output_size(), kernel_initializer='he_normal',\n",
    "                  name='dense2')(concatenate([gru_2, gru_2b]))\n",
    "    y_pred = Activation('softmax', name='softmax')(inner)\n",
    "#     Model(inputs=input_data, outputs=y_pred).summary()\n",
    "\n",
    "    labels = Input(name='the_labels', shape=[img_gen.absolute_max_string_len], dtype='float32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "    # Keras doesn't currently support loss funcs with extra parameters\n",
    "    # so CTC loss is implemented in a lambda layer\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "\n",
    "    # clipnorm seems to speeds up convergence\n",
    "    sgd = SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n",
    "\n",
    "    model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
    "    model.summary()\n",
    "    # the loss calc occurs elsewhere, so use a dummy lambda func for the loss\n",
    "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)\n",
    "    if start_epoch > 0:\n",
    "        weight_file = os.path.join(OUTPUT_DIR, os.path.join(run_name, 'weights%02d.h5' % (start_epoch - 1)))\n",
    "        model.load_weights(weight_file)\n",
    "    # captures output of softmax so we can decode the output during visualization\n",
    "    test_func = K.function([input_data], [y_pred])\n",
    "\n",
    "    viz_cb = VizCallback(run_name, test_func, img_gen.next_val())\n",
    "\n",
    "    model.fit_generator(generator=img_gen.next_train(),\n",
    "                        steps_per_epoch=(words_per_epoch - val_words) // minibatch_size,\n",
    "                        epochs=stop_epoch,\n",
    "                        validation_data=img_gen.next_val(),\n",
    "                        validation_steps=val_words // minibatch_size,\n",
    "                        callbacks=[viz_cb, img_gen],\n",
    "                        initial_epoch=start_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          (None, 128, 64, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 128, 64, 16)  160         the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max1 (MaxPooling2D)             (None, 64, 32, 16)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 64, 32, 16)   2320        max1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "max2 (MaxPooling2D)             (None, 32, 16, 16)   0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 32, 256)      0           max2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 32, 32)       8224        reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru1 (GRU)                      (None, 32, 512)      837120      dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru1_b (GRU)                    (None, 32, 512)      837120      dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 32, 512)      0           gru1[0][0]                       \n",
      "                                                                 gru1_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru2 (GRU)                      (None, 32, 512)      1574400     add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru2_b (GRU)                    (None, 32, 512)      1574400     add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 1024)     0           gru2[0][0]                       \n",
      "                                                                 gru2_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 32, 28)       28700       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 32, 28)       0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "the_labels (InputLayer)         (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "label_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc (Lambda)                    (None, 1)            0           softmax[0][0]                    \n",
      "                                                                 the_labels[0][0]                 \n",
      "                                                                 input_length[0][0]               \n",
      "                                                                 label_length[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,862,444\n",
      "Trainable params: 4,862,444\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/25\n",
      "[[19.  7.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [17. 12. 15. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [14.  5. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 0. 17. 15. 19. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 0. 13.  3. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 0. 23. 14. 13. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [19. 14. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [15.  3. 14. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 0. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 1. 14. 17.  3. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 8. 13. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 3.  3.  8. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 5. 14. 17. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [15. 14. 11. 18. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 8. 18. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [15. 11.  0. 18. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [14. 13. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [13.  0.  2.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [19.  7.  0. 19. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 6.  3. 17. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 1. 24. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [15. 16.  8. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [19.  7.  8. 18. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [14. 17. 12. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [22.  8. 19.  7. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 2.  2.  8.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 8. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [14. 17. 11. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [24. 14. 20. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [27.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [27.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [27.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "[[13. 14. 19. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 6. 11. 15. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [14. 17. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [21.  8. 14. 11. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 1.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [19.  0. 17. 15. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 0. 17.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 0. 19.  4. 13. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 5. 17. 14. 12. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [17.  0. 20. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 0. 19. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [12.  8. 10.  8. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 0. 18. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 2. 12.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [24. 14. 20. 17. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [13. 16.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 0. 11. 11. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 4. 11. 15. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 7.  0. 21.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [15. 20. 13. 24. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [13.  4. 22. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 8. 13.  6.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [12. 14. 17.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [12.  8. 18. 14. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 0. 13. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 8. 19. 23. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [22.  0. 18. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 1. 15.  3. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [22.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [27.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [27.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [27.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "[[ 2.  0. 13. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [21. 13.  3. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [20. 18. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 2. 18. 23. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 8.  5. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 2. 17.  4.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [15.  0.  6.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 5.  8. 25. 25. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [12. 24. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 5. 14.  2.  8. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 7.  0. 18. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [15. 19.  7. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 5. 17.  4.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 3. 17.  0.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 1. 20. 19. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [10.  4.  2. 10. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [14. 20. 17. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 4.  8.  2. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [14. 13.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 1.  0.  2.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 3. 14. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [15. 21. 18. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [13. 14. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 9.  0. 11. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [19.  8. 12.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [21. 19. 10. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [19.  7.  4. 24. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 3.  2. 19. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [18.  8. 19.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [27.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [27.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [27.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "[[20. 15. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 2. 18. 19. 21. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [12.  0. 24. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [17.  0. 25.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [22.  7.  0. 19. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 1. 14.  7. 17. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [13.  4. 22. 18. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [18. 20.  5.  8. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [14. 20. 19. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 0.  5.  3.  2. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [20. 18.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [15. 17.  4. 25. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 0. 13. 24. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [11. 18. 11. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [18.  4.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [20. 18.  5. 18. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [14. 13. 11. 24. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [10. 20. 19.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [18. 14. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [18. 17.  6. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 7.  8. 18. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [20. 21. 12. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [22.  7.  4. 13. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 7.  2. 15. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 7.  4. 17.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 5. 11.  0. 10. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [22.  4.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [20.  0. 11. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 0. 11. 18. 14. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [27.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [27.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [27.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.  4. 11. 15. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [15.  8. 11. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 6.  4. 19. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [19.  7. 19. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [15. 12. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [12.  3.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [21.  8.  4. 22. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 4. 19. 13.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 2. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 4. 22. 18. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 9. 17. 18. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 0. 12. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [16. 20. 14.  3. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 1.  4.  4. 13. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 5.  4. 19. 19. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [22.  4. 17.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [15.  2. 14. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [12.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 0.  1. 11. 24. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [18. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [11.  8.  0. 14. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [18. 14. 12.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 1. 17. 20. 13. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 8. 19. 18. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [21. 12.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [11.  8. 10.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [20. 22.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [23. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [27.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [27.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [27.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "[[ 5.  8. 13.  3. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [14.  5.  3. 12. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 3.  0. 19.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 0.  8. 11. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 1.  0.  2. 10. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [13.  2.  4. 15. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [19. 14. 15. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [17.  4.  3.  3. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 7.  0.  3. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [17. 19. 19. 24. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [11.  8. 18. 19. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 5. 12. 11.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [13.  0. 12.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 0. 17.  0. 13. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 9. 20. 18. 19. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 2.  5.  8. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [14. 21.  4. 17. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [11.  0. 17.  3. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [24.  4.  0. 17. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [14. 12.  8.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 3.  0. 24. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [13.  4. 17.  2. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 8. 13. 19. 14. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [19.  4. 14. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [19. 22. 14. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 7. 24. 15. 14. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [13. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [12. 22.  2. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [17.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [27.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [27.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [27.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "[[20. 18.  4.  3. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [18. 14.  8. 19. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 6. 14. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 9. 17.  2. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 6.  8. 17. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [22. 14. 17. 10. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 9. 16. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [11.  0. 18. 19. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [17.  3.  2. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [12. 14. 18. 19. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 9. 14.  3. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 1. 20. 24. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 2.  4. 15. 19. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 3.  0. 19.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 2.  7.  0. 25. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [12.  0. 10.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [18. 18.  7.  3. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [19.  7.  4. 12. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 6. 11.  2. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [15. 14. 18. 19. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [18.  5. 13. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 7.  4. 17. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 1.  0. 18. 20. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 2.  8. 19. 24. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 1. 10. 18. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [19. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 9. 14. 19.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 0.  3.  3. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [27.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [27.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [27.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "[[ 1.  4. 18. 19. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [20.  4. 18. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [19.  7.  4. 13. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [18.  8.  5.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 9.  0. 13. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 1.  0.  4. 25. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 6. 14. 14.  3. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [19.  0. 13.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [22.  4. 11. 11. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [20. 21.  2. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 3. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [18.  4.  2.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 8. 13.  5. 14. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [17.  8. 13.  3. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 7.  8.  6.  7. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 1.  1. 17. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [12. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [17.  0. 17.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 4.  0.  2.  7. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [21.  4. 11. 14. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [18.  7.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 0.  2.  2.  2. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [21.  4. 17. 24. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 8.  8.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 1. 14. 14. 10. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 1. 20. 17. 11. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [17. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [18.  2.  6. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [17.  4.  0.  3. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [27.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [27.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [27.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "[[12.  0. 13. 24. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [20. 14. 12. 14. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [20. 18.  4. 17. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 0. 18. 16. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [18.  0.  8.  3. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [25. 14. 14. 11. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 3.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [17.  5. 15. 18. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 3. 14.  4. 18. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 8. 11.  2. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [18.  4. 19. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 4. 13. 22. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [12.  0.  8. 11. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [12.  4.  8. 17. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [12.  0. 15. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [19. 15. 17. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [11.  8.  5.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 0.  3.  4. 13. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [10. 13. 14. 22. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 5.  7. 18. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [22.  0. 24. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 9.  4.  6. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 3.  0. 24. 18. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 0. 15. 15. 25. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [15. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 4.  2. 11. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [15.  0. 17. 19. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [19. 18. 21. 13. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [17.  4.  0. 11. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [27.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [27.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [27.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "[[ 8. 19.  4. 12. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [14.  6. 14. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 4.  1.  0. 24. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 8. 11. 10. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [12. 20. 18. 19. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [14. 18.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [14.  5.  5. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [12. 10. 18. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [11.  8. 13.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 6. 15. 23. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 3.  8.  3. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [13.  0. 10.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [18.  4. 13.  3. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [22. 19. 15. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [19. 24. 15.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [18.  2. 13. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 2.  0. 17. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 2.  8.  6. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [19.  0. 10.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [24.  0.  3.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 0. 17.  4.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 1. 12.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [22.  0. 13. 19. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [17. 20. 18.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 3. 21.  3. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [15. 10.  2. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [11. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 3. 14. 21. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [11. 14. 13.  6. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [27.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [27.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [27.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2. 14.  3.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [11. 17. 18. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [14. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 5. 15. 20. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 4. 21.  4. 13. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 5. 19. 18. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [12. 20.  2.  7. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [12.  0. 13.  6. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [18.  8.  6. 13. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [11. 20.  8. 25. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 5.  8. 11.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 8. 13.  3.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [11.  8. 13. 10. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [23. 16. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [14. 15.  4. 13. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [19.  4. 21. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 2.  0. 18.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 3. 22. 17. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [18.  0. 12.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 8. 19.  8. 18. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 1. 14. 19.  7. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [18.  0. 10. 18. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 6. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 2. 17. 14.  2. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 6.  0. 12.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 5. 19.  4. 18. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 2.  0. 17.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 0. 14.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 4. 13.  3. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [27.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [27.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [27.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[32,16,128,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: conv1_3/convolution = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv1_3/convolution-0-TransposeNHWCToNCHW-LayoutOptimizer, conv1_3/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss_3/mul/_371 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_5572_loss_3/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op u'conv1_3/convolution', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 1064, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2714, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2824, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2878, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-11-68aae85ee6e6>\", line 4, in <module>\n    train(run_name, 0, 25, 128)\n  File \"<ipython-input-9-5010bebd304b>\", line 36, in train\n    name='conv1')(input_data)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/layers/convolutional.py\", line 168, in call\n    dilation_rate=self.dilation_rate)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py\", line 3335, in conv2d\n    data_format=tf_data_format)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.py\", line 782, in convolution\n    return op(input, filter)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.py\", line 870, in __call__\n    return self.conv_op(inp, filter)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.py\", line 522, in __call__\n    return self.call(inp, filter)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.py\", line 206, in __call__\n    name=self.name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 953, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,16,128,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: conv1_3/convolution = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv1_3/convolution-0-TransposeNHWCToNCHW-LayoutOptimizer, conv1_3/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss_3/mul/_371 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_5572_loss_3/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-68aae85ee6e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# increase to wider images and start at epoch 20. The learned weights are reloaded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-5010bebd304b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(run_name, start_epoch, stop_epoch, img_w)\u001b[0m\n\u001b[1;32m     89\u001b[0m                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_words\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mminibatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mviz_cb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_gen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                         initial_epoch=start_epoch)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2222\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2223\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2224\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2226\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[32,16,128,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: conv1_3/convolution = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv1_3/convolution-0-TransposeNHWCToNCHW-LayoutOptimizer, conv1_3/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss_3/mul/_371 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_5572_loss_3/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op u'conv1_3/convolution', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 1064, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2714, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2824, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2878, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-11-68aae85ee6e6>\", line 4, in <module>\n    train(run_name, 0, 25, 128)\n  File \"<ipython-input-9-5010bebd304b>\", line 36, in train\n    name='conv1')(input_data)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/layers/convolutional.py\", line 168, in call\n    dilation_rate=self.dilation_rate)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py\", line 3335, in conv2d\n    data_format=tf_data_format)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.py\", line 782, in convolution\n    return op(input, filter)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.py\", line 870, in __call__\n    return self.conv_op(inp, filter)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.py\", line 522, in __call__\n    return self.call(inp, filter)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.py\", line 206, in __call__\n    name=self.name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 953, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,16,128,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: conv1_3/convolution = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv1_3/convolution-0-TransposeNHWCToNCHW-LayoutOptimizer, conv1_3/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss_3/mul/_371 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_5572_loss_3/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "run_name = datetime.datetime.now().strftime('%Y:%m:%d:%H:%M:%S')\n",
    "    \n",
    "    # increase to wider images and start at epoch 20. The learned weights are reloaded\n",
    "train(run_name, 0, 25, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_h = 64\n",
    "img_w = 512\n",
    "words_per_epoch = 16000\n",
    "val_split = 0.2\n",
    "val_words = int(words_per_epoch * (val_split))\n",
    "\n",
    "# Network parameters\n",
    "conv_filters = 16\n",
    "kernel_size = (3, 3)\n",
    "pool_size = 2\n",
    "time_dense_size = 32\n",
    "rnn_size = 512\n",
    "minibatch_size = 32\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (1, img_w, img_h)\n",
    "else:\n",
    "    input_shape = (img_w, img_h, 1)\n",
    "\n",
    "fdir = os.path.dirname(get_file('wordlists.tgz',\n",
    "                                origin='http://www.mythic-ai.com/datasets/wordlists.tgz', untar=True))\n",
    "\n",
    "img_gen2 = TextImageGenerator(monogram_file=os.path.join(fdir, 'wordlist_mono_clean.txt'),\n",
    "                             bigram_file=os.path.join(fdir, 'wordlist_bi_clean.txt'),\n",
    "                             minibatch_size=minibatch_size,\n",
    "                             img_w=img_w,\n",
    "                             img_h=img_h,\n",
    "                             downsample_factor=(pool_size ** 2),\n",
    "                             val_split=words_per_epoch - val_words\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TextImageGenerator' object has no attribute 'paint_func'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-c0a90e9bbd38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimg_gen2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-4bbd8d40e1d4>\u001b[0m in \u001b[0;36mget_batch\u001b[0;34m(self, index, size, train)\u001b[0m\n\u001b[1;32m    206\u001b[0m                     \u001b[0mX_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaint_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m                     \u001b[0mX_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaint_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m                 \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                 \u001b[0minput_length\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_w\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample_factor\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TextImageGenerator' object has no attribute 'paint_func'"
     ]
    }
   ],
   "source": [
    "\n",
    "img_gen2.get_batch(3,16,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "on_batch_begin() takes at least 2 arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-d5cf924ed1ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg_gen2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: on_batch_begin() takes at least 2 arguments (1 given)"
     ]
    }
   ],
   "source": [
    "img_gen2.on_batch_begin()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TextImageGenerator' object has no attribute 'cur_train_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-ebb6734fc1da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Text generator output (data which will be fed into the neutral network):'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1) the_input (image)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'channels_first'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'the_input'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-4bbd8d40e1d4>\u001b[0m in \u001b[0;36mnext_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcur_train_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminibatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcur_train_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminibatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcur_train_index\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_split\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TextImageGenerator' object has no attribute 'cur_train_index'"
     ]
    }
   ],
   "source": [
    "for inp, out in img_gen.next_train():\n",
    "    print('Text generator output (data which will be fed into the neutral network):')\n",
    "    print('1) the_input (image)')\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        img = inp['the_input'][0, 0, :, :]\n",
    "    else:\n",
    "        img = inp['the_input'][0, :, :, 0]\n",
    "    \n",
    "    plt.imshow(img.T, cmap='gray')\n",
    "    plt.show()\n",
    "    print('2) the_labels (plate number): %s is encoded as %s' % \n",
    "          (labels_to_text(inp['the_labels'][0]), list(map(int, inp['the_labels'][0]))))\n",
    "    print('3) input_length (width of image that is fed to the loss function): %d == %d / 4 - 2' % \n",
    "          (inp['input_length'][0], tiger.img_w))\n",
    "    print('4) label_length (length of plate number): %d' % inp['label_length'][0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
